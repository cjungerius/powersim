@article{adamClassicVisualSearch2021,
  title = {Classic {{Visual Search Effects}} in an {{Additional Singleton Task}}: {{An Open Dataset}}},
  shorttitle = {Classic {{Visual Search Effects}} in an {{Additional Singleton Task}}},
  author = {Adam, Kirsten C. S. and Patel, Titiksha and Rangan, Nicole and Serences, John T.},
  year = {2021},
  month = jul,
  volume = {4},
  number = {1},
  pages = {34},
  publisher = {{Ubiquity Press}},
  issn = {2514-4820},
  doi = {10.5334/joc.182},
  urldate = {2024-01-02},
  abstract = {Visual search refers to our ability to find what we are looking for among many competing visual inputs. Here, we report the availability of a rich dataset that replicates key visual search effects and shows that these effects are robust to several changes to the experimental design. Experiment 1 replicates classic findings from an additional singleton visual search task. First, participants are captured by a salient but irrelevant color singleton, as indexed by slower response times when a color singleton distractor is present versus absent. Second, attentional capture by a color singleton is reduced when the visual search array contains heterogeneous shapes rather than homogenous shapes. Finally, attentional capture by a color singleton is reduced when the display colors are repeated rather than switched unpredictably from trial to trial. Experiment 2 demonstrates that these classic visual search effects are robust to small procedural changes such as task timing (i.e., a 2{\textendash}8 second rather than {\textasciitilde}1 second intertrial interval). Experiment 3 demonstrates that these classic effects are likewise robust to changes to the distractor frequency (75\% rather than 50\%) and to fully blocking versus interleaving blocks of two task conditions. All told, this dataset includes 8 sub-experiments, 190 participants and \&gt;210,000 trials, and it will serve as a useful resource~for power analyses and exploratory analyses of visual search behaviors.},
  langid = {american},
  file = {C:\Users\cjung\Zotero\storage\B5WA2QHW\Adam et al. - 2021 - Classic Visual Search Effects in an Additional Sin.pdf}
}

@misc{debruineAppendix1cSensitivity2020,
  title = {Appendix 1c: {{Sensitivity Analysis}}},
  shorttitle = {Appendix 1c},
  author = {DeBruine, Lisa M. and Barr, Dale J.},
  year = {2020},
  month = aug,
  urldate = {2022-12-06},
  abstract = {lmem.sim},
  howpublished = {https://debruine.github.io/lmem\_sim/articles/appendix1c\_sensitivity.html},
  langid = {english},
  file = {C:\Users\cjung\Zotero\storage\5KVSSIR6\appendix1c_sensitivity.html}
}

@manual{debruineFauxSimulationFactorial2023,
  type = {Manual},
  title = {Faux: {{Simulation}} for Factorial Designs},
  author = {DeBruine, Lisa},
  year = {2023},
  institution = {{Zenodo}},
  doi = {10.5281/zenodo.2669586}
}

@article{debruineUnderstandingMixedEffectsModels2021,
  title = {Understanding {{Mixed-Effects Models Through Data Simulation}}},
  author = {DeBruine, Lisa M. and Barr, Dale J.},
  year = {2021},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {1},
  pages = {2515245920965119},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245920965119},
  urldate = {2022-08-10},
  abstract = {Experimental designs that sample both subjects and stimuli from a larger population need to account for random effects of both subjects and stimuli using mixed-effects models. However, much of this research is analyzed using analysis of variance on aggregated responses because researchers are not confident specifying and interpreting mixed-effects models. This Tutorial explains how to simulate data with random-effects structure and analyze the data using linear mixed-effects regression (with the lme4 R package), with a focus on interpreting the output in light of the simulated parameters. Data simulation not only can enhance understanding of how these models work, but also enables researchers to perform power calculations for complex designs. All materials associated with this article can be accessed at https://osf.io/3cz2e/.},
  langid = {english},
  keywords = {lme4,mixed-effects models,open materials,power,R,simulation},
  file = {C:\Users\cjung\Zotero\storage\9WQBW56B\DeBruine and Barr - 2021 - Understanding Mixed-Effects Models Through Data Si.pdf}
}

@misc{kurzBayesianPowerAnalysis2021,
  title = {Bayesian Power Analysis: {{Part I}}. {{Prepare}} to Reject `{\textbackslash}({{H}}\_0{\textbackslash})` with Simulation.},
  shorttitle = {Bayesian Power Analysis},
  author = {Kurz, A. Solomon},
  year = {2021},
  month = apr,
  journal = {A. Solomon Kurz},
  urldate = {2024-01-02},
  abstract = {If you'd like to learn how to do Bayesian power calculations using **brms**, stick around for this multi-part blog series. Here with part I, we'll set the foundation.},
  howpublished = {https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/},
  langid = {english},
  file = {C:\Users\cjung\Zotero\storage\P7LQ49XP\bayesian-power-analysis-part-i.html}
}

@article{lakensEquivalenceTestingPsychological2018,
  title = {Equivalence {{Testing}} for {{Psychological Research}}: {{A Tutorial}}},
  shorttitle = {Equivalence {{Testing}} for {{Psychological Research}}},
  author = {Lakens, Dani{\"e}l and Scheel, Anne M. and Isager, Peder M.},
  year = {2018},
  month = jun,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {2},
  pages = {259--269},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245918770963},
  urldate = {2024-01-02},
  abstract = {Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects.},
  langid = {english},
  file = {C:\Users\cjung\Zotero\storage\H64DYLA8\Lakens et al. - 2018 - Equivalence Testing for Psychological Research A .pdf}
}
